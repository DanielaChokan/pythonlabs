import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
import matplotlib.pyplot as plt
from collections import Counter

# Завантаження стоп-слів
nltk.download('stopwords')
stop_words = set(stopwords.words('english'))

# Завантаження тексту з файлу
file_path = r'C:\Users\HP\Downloads\edgeworth-parents.txt'
with open(file_path, 'r', encoding='utf-8') as file:
    text = file.read()

# Токенізація слів
words = word_tokenize(text)

# Визначення кількості слів у тексті
word_count = len(words)
print(f"Кількість слів у тексті: {word_count}")

# Знайти 10 найбільш вживаних слів та побудувати стовпчасту діаграму
word_freq = Counter(words)
top_words, top_freq = zip(*word_freq.most_common(10))

plt.figure(figsize=(10, 6))
plt.bar(top_words, top_freq, color='skyblue')
plt.title('10 найбільш вживаних слів у тексті')
plt.xlabel('Слова')
plt.ylabel('Частота')
plt.show()

# Видалення стоп-слів та пунктуації
filtered_words = [word.lower() for word in words if word.isalnum() and word.lower() not in stop_words]

# Знайти 10 найбільш вживаних слів після видалення стоп-слів та пунктуації
filtered_word_freq = Counter(filtered_words)
filtered_top_words, filtered_top_freq = zip(*filtered_word_freq.most_common(10))

# Побудова стовпчастої діаграми після видалення стоп-слів та пунктуації
plt.figure(figsize=(10, 6))
plt.bar(filtered_top_words, filtered_top_freq, color='lightcoral')
plt.title('10 найбільш вживаних слів після видалення стоп-слів та пунктуації')
plt.xlabel('Слова')
plt.ylabel('Частота')
plt.show()
